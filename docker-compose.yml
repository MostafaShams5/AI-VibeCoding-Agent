version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_service
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama
    # optimization: Keep model in RAM longer so it doesn't reload between steps
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    networks:
      - agent_network

  agent:
    build: .
    container_name: vibe_agent
    depends_on:
      - ollama
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      # Use the 1.5B model. faster on CPU.
      - LLM_MODEL=qwen2.5-coder:1.5b
      # Increase max retries because smaller models might need an extra try
      - MAX_RETRIES=3
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
    networks:
      - agent_network
    command: tail -f /dev/null

networks:
  agent_network:
    driver: bridge

volumes:
  ollama_storage:
